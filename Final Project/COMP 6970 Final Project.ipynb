{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cody Nichols' COMP 6970 Final Project\n",
    "This will be where I test and compile my final results from my findings.\n",
    "\n",
    "- Paper 1\n",
    "    - ~~Read Paper~~\n",
    "    - ~~Implement Bullish/Bearish Classification with NN Structure~~\n",
    "    - ~~Implement Candlestick Classification with NN Structure~~\n",
    "- Paper 2\n",
    "    - ~~Read Paper~~\n",
    "    - Implement MS-CNN Architecture\n",
    "    - Create DDQN Architecture\n",
    "- Paper 3 (Time Permitting)\n",
    "- Complete Project\n",
    "    - Combine Code (in this ipynb)\n",
    "        - Implement Dataset Curation\n",
    "        - Create my own version of Paper 1\n",
    "        - Create my own version of Paper 2\n",
    "        - Combine the outputs of Paper 1 and 2's vision components as inputs for Paper 2's DDQN\n",
    "    - Write Paper\n",
    "    - Create Presentation\n",
    "    - Make Recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 1 Rendition\n",
    "Paper 1 (Empowering Financial Technical Analysis Using Computer Vision Techniques) creates a CNN architecture that classifies candlestick charts in 2 ways. The first classification is a binary classification of bullish or bearish for a 20-candlestick image. The second classification is a multi-class classification of candlestick pattern type based on each individual candlestick and some surrounding candlesticks. The CNN architecture is 14-layer CNN with a 8 convolution layers, 3 max pooling layers, a VGG-16 pretrained preprocessing layer, a fully connected layer, and an output layer. This architecture was implemented in paper1.ipynb for the binary classification task, but was not used for the multi-class classification task. The reasoning behind not using it for the multi-class classification task was because of the ambiguity on how the model was trained. The assumed training method was dividing up the candlestick charts into smaller images to make classification on each candlestick and labeling each image easier, but there were some issues with the images I created not being big enough to make it all the way through without needing to size them back up. \n",
    "\n",
    "In this notebook, I will perform the same classification tasks with the knowledge that I have gained from implementing the author's solution to achieve the best accuracy on the binary classification and the best per-class accuracy for the multi-class classifcation. This per-class accuracy is because I will be having \"None\" labels in my candlesticks (unlike the author of Paper 1) because most candlesticks in candlestick charts do not have a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from pyts.image import GramianAngularField\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
