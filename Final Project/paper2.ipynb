{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from collections import deque\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA GeForce GTX 1660 Ti\n",
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OHLCVDataset(Dataset):\n",
    "    def __init__(self, file_path, window_size=20):\n",
    "        self.window_size = window_size\n",
    "        self.data = pd.read_csv(file_path, parse_dates=[\"datetime\"])\n",
    "        self.raw_data = self.data[[\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "        self.data['date'] = self.data['datetime'].dt.date\n",
    "        self.grouped = self.data.groupby('date')\n",
    "\n",
    "        self.daily_data = []\n",
    "        for date, group in self.grouped:\n",
    "            if len(group) >= self.window_size:\n",
    "                self.daily_data.append(group.reset_index(drop=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.daily_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        day_data = self.daily_data[idx]\n",
    "        raw_data = day_data[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].values\n",
    "        normalized_data = self._normalize(raw_data)\n",
    "\n",
    "        states = []\n",
    "        for i in range(len(normalized_data) - self.window_size + 1):\n",
    "            state = normalized_data[i : i + self.window_size]\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32).transpose(0, 1)\n",
    "            state_tensor = state_tensor.unsqueeze(0).unsqueeze(0)\n",
    "            states.append(state_tensor)\n",
    "        return {\n",
    "            'states': states,\n",
    "            'raw_data': raw_data,\n",
    "            'datetimes': day_data['datetime'].values[self.window_size - 1 :],\n",
    "            'dates': day_data['date'].iloc[0]\n",
    "        }\n",
    "\n",
    "    def _normalize(self, data):\n",
    "        min_vals = data.min(axis=0)\n",
    "        max_vals = data.max(axis=0)\n",
    "        return (data - min_vals) / (max_vals - min_vals + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleScale1D(nn.Module):\n",
    "    def __init__(self, input_channels=5, output_channels=5, kernel_size=3):\n",
    "        super(SingleScale1D, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=kernel_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeByThreeConv2D(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_channels=2, kernel_size=3):\n",
    "        super(ThreeByThreeConv2D, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiveByFiveConv2D(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_channels=1, kernel_size=5):\n",
    "        super(FiveByFiveConv2D, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=kernel_size, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleNet(nn.Module):\n",
    "    def __init__(self, height=5, width=20):\n",
    "        super(MultiScaleNet, self).__init__()\n",
    "        self.single_scale_1d = SingleScale1D(input_channels=5, output_channels=5, kernel_size=3)\n",
    "        self.three_by_three = ThreeByThreeConv2D(input_channels=1, output_channels=2, kernel_size=3)\n",
    "        self.five_by_five = FiveByFiveConv2D(input_channels=1, output_channels=1, kernel_size=5)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 1, height, width)\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        \n",
    "        # Reshape x for SingleScale1D\n",
    "        x_1d = x.view(batch_size, height, width)  # Remove channel dimension: (batch_size, 5, window_size)\n",
    "        features_1d = self.single_scale_1d(x_1d)  # Output shape: (batch_size, 5, new_time_length)\n",
    "\n",
    "        # Pooling and upsampling to match 2D dimensions\n",
    "        features_1d = features_1d.mean(dim=2, keepdim=True)  # Global average pooling along time dimension\n",
    "        features_1d = features_1d.view(batch_size, 5, 1, 1)  # Reshape to (batch_size, 5, 1, 1)\n",
    "        features_1d = F.interpolate(features_1d, size=(height, width), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Apply 3x3 and 5x5 Convolutions\n",
    "        features_3x3 = self.three_by_three(x)  # Output shape: (batch_size, 2, height, width)\n",
    "        features_5x5 = self.five_by_five(x)    # Output shape: (batch_size, 1, height, width)\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        combined_features = torch.cat((features_1d, features_3x3, features_5x5), dim=1)\n",
    "        \n",
    "        return combined_features  # Shape: (batch_size, 8, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECABlock(nn.Module):\n",
    "    def __init__(self, channels, gamma=2, b=1):\n",
    "        super(ECABlock, self).__init__()\n",
    "        t = int(abs((math.log(channels, 2) + b) / gamma))\n",
    "        k = t if t % 2 else t + 1  # Ensure k is odd\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, channels, height, width)\n",
    "        y = self.avg_pool(x)  # (batch_size, channels, 1, 1)\n",
    "        y = y.squeeze(-1).transpose(-1, -2)  # (batch_size, 1, channels)\n",
    "        y = self.conv(y)\n",
    "        y = self.sigmoid(y)\n",
    "        y = y.transpose(-1, -2).unsqueeze(-1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, input_channels=8):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.eca = ECABlock(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.eca(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSNetWithBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSNetWithBackbone, self).__init__()\n",
    "        self.multi_scale_net = MultiScaleNet()\n",
    "        self.backbone = Backbone(input_channels=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First pass through multi-scale net\n",
    "        x = self.multi_scale_net(x)\n",
    "        # Pass through backbone with attention\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSNetWithQValue(nn.Module):\n",
    "    def __init__(self, num_actions=3):\n",
    "        super(MSNetWithQValue, self).__init__()\n",
    "        self.multi_scale_with_backbone = MSNetWithBackbone()\n",
    "\n",
    "        # Additional Conv3x3 layer before the linear layers\n",
    "        self.conv_final = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Determine the input size for the fully connected layers\n",
    "        sample_input = torch.randn(1, 1, 5, 20)\n",
    "        sample_output = self.multi_scale_with_backbone(sample_input)\n",
    "        sample_output = self.conv_final(sample_output)\n",
    "        feature_map_size = sample_output.view(-1).size(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(feature_map_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.multi_scale_with_backbone(x)\n",
    "        x = self.conv_final(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create MS-CNN and ensure the output shape is the correct size (3 Q values: 1 for each action)\n",
    "model = MSNetWithQValue(num_actions=3)\n",
    "test_input = torch.randn(1, 1, 5, 20)\n",
    "output = model(test_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    # Initialize buffer as a double ended queue\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    # Push a state, action, reward, next_state, done combination on the buffer\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # Randomly sample\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = zip(*batch)\n",
    "        state_batch = torch.cat(state, dim=0)\n",
    "        next_state_batch = torch.cat(next_state, dim=0)\n",
    "        return (\n",
    "            state_batch,\n",
    "            torch.tensor(action, dtype=torch.long),\n",
    "            torch.tensor(reward, dtype=torch.float32),\n",
    "            next_state_batch,\n",
    "            torch.tensor(done, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    # Override buffer's length method and return length\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent:\n",
    "    def __init__(self, buffer_capacity, gamma=0.99, lr=1e-3, target_update_freq=100):\n",
    "        self.actor = MSNetWithQValue()\n",
    "        self.target = MSNetWithQValue()\n",
    "        self.target.load_state_dict(self.actor.state_dict())\n",
    "        self.target.eval()\n",
    "\n",
    "        self.buffer = ReplayBuffer(buffer_capacity)\n",
    "        self.optimizer = optim.Adam(self.actor.parameters(), lr=lr)\n",
    "        self.gamma = gamma\n",
    "        self.target_update_freq = target_update_freq\n",
    "        self.steps = 0\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "\n",
    "        self.position = 'sold_out'\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, 2)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.actor(state)\n",
    "                max_q, max_action = q_values.max(dim=1)\n",
    "                max_action = max_action.item()\n",
    "                \n",
    "                if self.position == 'bought_in':\n",
    "                    if max_action in [0, 1]:\n",
    "                        return 0\n",
    "                elif max_action == 2:\n",
    "                    return 2\n",
    "                elif self.position == 'sold_out':\n",
    "                    if max_action in [0, 2]:\n",
    "                        return 0\n",
    "                    elif max_action == 1:\n",
    "                        return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def train(self, batch_size):\n",
    "        if len(self.buffer) < batch_size:\n",
    "            return\n",
    "\n",
    "        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.buffer.sample(batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.actor(next_state_batch)\n",
    "            next_actions = next_q_values.argmax(dim=1)\n",
    "            target_q_values = self.target(next_state_batch)\n",
    "            target_q = reward_batch + self.gamma * (1 - done_batch) * target_q_values[range(batch_size), next_actions]\n",
    "\n",
    "        current_q = self.actor(state_batch)[range(batch_size), action_batch]\n",
    "\n",
    "        loss = F.mse_loss(current_q, target_q)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.steps % self.target_update_freq == 0:\n",
    "            self.target.load_state_dict(self.actor.state_dict())\n",
    "\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "        self.steps += 1\n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        self.buffer.push(state, action, reward, next_state, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnvWithFeatures:\n",
    "    def __init__(self, daily_dataset, k=5):\n",
    "        self.daily_dataset = daily_dataset\n",
    "        self.current_day = 0\n",
    "        self.num_days = len(daily_dataset)\n",
    "        self.k = k\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.price_history = []\n",
    "        self.initial_cash = 500000\n",
    "        self.cash_balance = self.initial_cash\n",
    "        self.total_asset_value = self.cash_balance\n",
    "        self.previous_total_asset_value = self.total_asset_value\n",
    "        self.trade_log = []\n",
    "        self.cost_basis = 0.0\n",
    "        self.shares_held = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.price_history = []\n",
    "        self.initial_cash = 500000\n",
    "        self.cash_balance = self.initial_cash\n",
    "        self.total_asset_value = self.cash_balance\n",
    "        self.previous_total_asset_value = self.total_asset_value\n",
    "        self.trade_log = []\n",
    "        self.cost_basis = 0.0\n",
    "        self.shares_held = 0\n",
    "\n",
    "        if self.current_day >= self.num_days:\n",
    "            self.done = True\n",
    "            return None\n",
    "\n",
    "        day_data = self.daily_dataset[self.current_day]\n",
    "        self.states = day_data['states']\n",
    "        self.raw_data = day_data['raw_data']\n",
    "        self.datetimes = day_data['datetimes']\n",
    "        self.window_size = self.states[0].shape[-1]\n",
    "        self.num_steps = len(self.states)\n",
    "        self.raw_close_prices = self.raw_data[self.window_size - 1 :, 3]\n",
    "\n",
    "        self.current_day += 1\n",
    "\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        if self.current_step >= self.num_steps:\n",
    "            self.done = True\n",
    "            return None\n",
    "\n",
    "        state = self.states[self.current_step]\n",
    "        current_close_price = self.raw_data[self.current_step + self.window_size - 1, 3]\n",
    "        self.price_history.append(current_close_price)\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_step + 1 < self.num_steps:\n",
    "            state = self.states[self.current_step]\n",
    "            current_close_price = self.raw_close_prices[self.current_step]\n",
    "            next_close_price = self.raw_close_prices[self.current_step + 1]\n",
    "            datetime = self.datetimes[self.current_step]\n",
    "\n",
    "            datetime = self.datetimes[self.current_step]\n",
    "\n",
    "            profit = 0\n",
    "\n",
    "            if action == 1:\n",
    "                if current_close_price == 0:\n",
    "                    num_shares = 0\n",
    "                else:\n",
    "                    num_shares = int(self.cash_balance / current_close_price)\n",
    "                total_cost = num_shares * current_close_price\n",
    "                self.cash_balance -= total_cost\n",
    "                self.shares_held += num_shares\n",
    "                self.cost_basis += total_cost\n",
    "\n",
    "            elif action == 2:\n",
    "                num_shares = self.shares_held\n",
    "                total_proceeds = num_shares * current_close_price\n",
    "                self.cash_balance += total_proceeds\n",
    "                self.shares_held = 0\n",
    "                profit = total_proceeds - self.cost_basis\n",
    "                self.cost_basis = 0\n",
    "            \n",
    "            else:\n",
    "                profit = 0.0\n",
    "\n",
    "            self.previous_total_asset_value = self.total_asset_value\n",
    "            self.total_asset_value = self.cash_balance + self.shares_held * current_close_price\n",
    "\n",
    "            profit = self.total_asset_value - self.previous_total_asset_value\n",
    "\n",
    "            reward = self.calculate_reward(action, current_close_price)\n",
    "\n",
    "            action_mapping = {0: 'Hold', 1: 'Buy', 2: 'Sell'}\n",
    "            trade_info = {\n",
    "                'datetime': datetime,\n",
    "                'action': action_mapping[action],\n",
    "                'reward': reward,\n",
    "                'profit': profit,\n",
    "                'total_asset_value': self.total_asset_value,\n",
    "                'cash_balance': self.cash_balance,\n",
    "                'shares_held': self.shares_held,\n",
    "                'position': 'bought_in' if self.shares_held > 0 else 'sold_out'\n",
    "            }\n",
    "            self.trade_log.append(trade_info)\n",
    "\n",
    "            self.current_step += 1\n",
    "            done = self.current_step >= self.num_steps - 1\n",
    "            return self._get_state(), reward, done, {}\n",
    "        else:\n",
    "            self.done = True\n",
    "            return None, 0, True, {}\n",
    "\n",
    "    def calculate_reward(self, action, current_close_price):\n",
    "        POS_t = 1 if self.shares_held > 0 else 0\n",
    "\n",
    "        R_k_t = []\n",
    "        for i in range(1, self.k + 1):\n",
    "            future_step = self.current_step + i\n",
    "            if future_step >= self.num_steps:\n",
    "                break\n",
    "            future_price = self.raw_close_prices[future_step]\n",
    "            if current_close_price == 0:\n",
    "                R_k_t_i = 0\n",
    "            else:\n",
    "                R_k_t_i = (future_price - current_close_price) / current_close_price\n",
    "            R_k_t.append(R_k_t_i)\n",
    "\n",
    "        if len(R_k_t) < 2:\n",
    "            SR_t = 0\n",
    "        else:\n",
    "            mean_R = np.mean(R_k_t)\n",
    "            std_R = np.std(R_k_t)\n",
    "            if std_R == 0:\n",
    "                SR_t = 0\n",
    "            else:\n",
    "                SR_t = mean_R / std_R\n",
    "\n",
    "        SSR_t = POS_t * SR_t\n",
    "\n",
    "        return SSR_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data, environment, agent, and variables\n",
    "file_path = \"./labeling/TQQQ_minute_data_cleaned_labeled_375days.csv\"\n",
    "dataset = OHLCVDataset(file_path)\n",
    "env = StockTradingEnvWithFeatures(dataset)\n",
    "agent = DDQNAgent(buffer_capacity=10000)\n",
    "batch_size = 32\n",
    "num_days = len(dataset)\n",
    "\n",
    "# For each day in the training dataset, train the DDQNAgent\n",
    "for day in range(num_days):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    # While still in the day, keep training on that day\n",
    "    while not done and state is not None:\n",
    "        # Select an action based upon Q values returned from MS-CNN\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        # Calculate what that action does\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Store the transition in the replay/lookback buffer\n",
    "        agent.store_transition(state, action, reward, next_state, done)\n",
    "\n",
    "        # Train agent by updating networks to perform better calculations\n",
    "        agent.train(batch_size)\n",
    "\n",
    "        # Update Agent's Position\n",
    "        if action == 1:\n",
    "            agent.position = 'bought_in'\n",
    "        elif action == 2:\n",
    "            agent.position = 'sold_out'\n",
    "\n",
    "        # Increment state and add reward to total reward\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    # If training day is done and shares are still being held, sell\n",
    "    if env.shares_held > 0:\n",
    "        last_close_price = env.raw_data[env.current_step + env.window_size - 1, 3]\n",
    "        total_proceeds = env.shares_held * last_close_price\n",
    "        profit = total_proceeds - env.cost_basis\n",
    "        env.cash_balance += total_proceeds\n",
    "        env.shares_held = 0\n",
    "        env.cost_basis = 0.0\n",
    "        env.total_asset_value = env.cash_balance\n",
    "\n",
    "        # Logging\n",
    "        trade_info = {\n",
    "            'datetime': env.datetimes[-1],\n",
    "            'action': 'Sell (EOD)',\n",
    "            'reward': 0.0,\n",
    "            'profit': profit,\n",
    "            'total_asset_value': env.total_asset_value,\n",
    "            'cash_balance': env.cash_balance,\n",
    "            'shares_held': env.shares_held,\n",
    "            'position': 'sold_out'\n",
    "        }\n",
    "        env.trade_log.append(trade_info)\n",
    "\n",
    "        # Update Agent's Position\n",
    "        agent.position = 'sold_out'\n",
    "\n",
    "    # Calculate profit and print training info\n",
    "    total_profit = env.total_asset_value - env.initial_cash\n",
    "    print(f\"Day {day + 1}/{num_days}, Total Reward: {total_reward}, Total Profit: {total_profit}\")\n",
    "\n",
    "    # Convert trade log to csv for each day to see what decisions the bot is making\n",
    "    trade_log = env.trade_log\n",
    "    trade_log_df = pd.DataFrame(trade_log)\n",
    "    trade_log_df.to_csv(f\"./testing/trade_log_day_{day + 1}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
